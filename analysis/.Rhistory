getwd()
dice = rbinom(n = 1000000, size = 1, prob = .5)
right = rbinom(n = 1000000, size = 1, prob = .8)
sum(dice==right)
dice = rbinom(n = 1000000, size = 1, prob = 1)
right = rbinom(n = 1000000, size = 1, prob = .8)
sum(dice==right)
dice
ttt <- c(1, 2)
ttt
2*ttt
library(readxl)
install.packages("readxl")
library(readxl)
library(nlme)
library(magrittr)
library(tidyverse)
help(install_github)
help(devtools::install_github)
install.packages("sumSome")
knitr::opts_chunk$set(echo = TRUE)
G <- simData(prop = 0.6, m = 5, B = 10, alpha = 0.4, p = TRUE, seed = 42)
library(sumSome)
G <- simData(prop = 0.6, m = 5, B = 10, alpha = 0.4, p = TRUE, seed = 42)
S <- c(1,2) # subset of interest
G
res <- sumStats(G = G, S = S, alternative = "lower", alpha = 0.4, truncFrom = 0.4, truncTo = 0.5)
res
summary(res)
discoveries(res) # lower confidence bound for the number of true discoveries
tdp(res) # lower confidence bound for the TDP
fdp(res) # upper confidence bound for the FDP
G <- simData(prop = 0.6, m = 5, B = 10, alpha = 0.05, p = TRUE, seed = 42)
S <- c(1,2) # subset of interest
res <- sumStats(G = G, S = S, alternative = "lower", alpha = 0.4, truncFrom = 0.4, truncTo = 0.5)
summary(res)
discoveries(res) # lower confidence bound for the number of true discoveries
tdp(res) # lower confidence bound for the TDP
fdp(res) # upper confidence bound for the FDP
G <- simData(prop = 0.05, m = 5, B = 10, alpha = 0.4, p = TRUE, seed = 42)
S <- c(1,2) # subset of interest
res <- sumStats(G = G, S = S, alternative = "lower", alpha = 0.4, truncFrom = 0.4, truncTo = 0.5)
summary(res)
discoveries(res) # lower confidence bound for the number of true discoveries
tdp(res) # lower confidence bound for the TDP
fdp(res) # upper confidence bound for the FDP
help(simData)
G
G <- simData(prop = 0.6, m = 5, B = 10, alpha = 0.4, p = TRUE, seed = 42)
G
G <- simData(prop = 0.6, m = 5, B = 10, alpha = 0.4, p = FALSE, seed = 42)
G
G <- simData(prop = 0.6, m = 5, B = 10, alpha = 0.4, p = FALSE, seed = 42)
S <- c(1,2) # subset of interest
res <- sumStats(G = G, S = S, alternative = "lower", alpha = 0.4, truncFrom = 0.4, truncTo = 0.5)
summary(res)
S
discoveries(res) # lower confidence bound for the number of true discoveries
tdp(res) # lower confidence bound for the TDP
fdp(res) # upper confidence bound for the FDP
G <- simData(prop = 0.6, m = 5, B = 10, alpha = 0.4, p = FALSE, seed = 42)
S <- c(1,2) # subset of interest
res <- sumStats(G = G, S = S, alternative = "lower", alpha = 0.4, truncFrom = 0.4, truncTo = 0.5)
summary(res)
discoveries(res) # lower confidence bound for the number of true discoveries
G <- simData(prop = 0.6, m = 5, B = 10, alpha = 0.4, p = TRUE, seed = 42)
S <- c(1,2) # subset of interest
res <- sumStats(G = G, S = S, alternative = "lower", alpha = 0.4, truncFrom = 0.4, truncTo = 0.5)
summary(res)
discoveries(res) # lower confidence bound for the number of true discoveries
tdp(res) # lower confidence bound for the TDP
fdp(res) # upper confidence bound for the FDP
help(anova)
citation("emmeans")
citation("lmer")
citation("lme4")
citation("car")
citation("stats")
ceil(2.3)
ceiling(2.3)
help(ln)
??ln
??log
log(10)
ln(10)
ln(2.71)
log(2.71)
log(2.716)
z_onetailed <- 1.64
z_pow80 <- 0.84
N_estim <- ceiling(4*(z_onetailed+z_pow80)^2/log((1+corr_SDA_CVF)/(1-corr_SDA_CVF)) + 3);
# lag1 autocorrelation of asynchronies
# (Semjen, Schulze & Vorberg 2000, figure 4G; Repp 2011, figure 8)
autocorr_lag1 <- 0.4
# data from Sasaki et al 2011
# SD of intertap interval
aux1_df = read.csv("Sasaki 2011 figure 3C.dat", sep='\t', header=TRUE) # ISI=250ms
aux2_df = read.csv("Sasaki 2011 figure 3D.dat", sep='\t', header=TRUE) # ISI=500ms
data_iti_Sasaki_df <- rbind(aux1_df, aux2_df)
# mean force
aux1_df = read.csv("Sasaki 2011 figure 5A.dat", sep='\t', header=TRUE) # ISI=250ms
aux2_df = read.csv("Sasaki 2011 figure 5B.dat", sep='\t', header=TRUE) # ISI=500ms
# merge mean force data
data_force_mean_Sasaki_df <- rbind(aux1_df, aux2_df)
# SD force
aux1_df = read.csv("Sasaki 2011 figure 5E.dat", sep='\t', header=TRUE) # ISI=250ms
aux2_df = read.csv("Sasaki 2011 figure 5F.dat", sep='\t', header=TRUE) # ISI=500ms
# merge SD force data
data_force_sd_Sasaki_df <- rbind(aux1_df, aux2_df)
# merge mean and sd force data
data_force_Sasaki_df <- full_join(data_force_mean_Sasaki_df, data_force_sd_Sasaki_df,
by=join_by(age,cond,isi))
library(tidyverse)
# lag1 autocorrelation of asynchronies
# (Semjen, Schulze & Vorberg 2000, figure 4G; Repp 2011, figure 8)
autocorr_lag1 <- 0.4
# data from Sasaki et al 2011
# SD of intertap interval
aux1_df = read.csv("Sasaki 2011 figure 3C.dat", sep='\t', header=TRUE) # ISI=250ms
aux2_df = read.csv("Sasaki 2011 figure 3D.dat", sep='\t', header=TRUE) # ISI=500ms
data_iti_Sasaki_df <- rbind(aux1_df, aux2_df)
# mean force
aux1_df = read.csv("Sasaki 2011 figure 5A.dat", sep='\t', header=TRUE) # ISI=250ms
aux2_df = read.csv("Sasaki 2011 figure 5B.dat", sep='\t', header=TRUE) # ISI=500ms
# merge mean force data
data_force_mean_Sasaki_df <- rbind(aux1_df, aux2_df)
# SD force
aux1_df = read.csv("Sasaki 2011 figure 5E.dat", sep='\t', header=TRUE) # ISI=250ms
aux2_df = read.csv("Sasaki 2011 figure 5F.dat", sep='\t', header=TRUE) # ISI=500ms
# merge SD force data
data_force_sd_Sasaki_df <- rbind(aux1_df, aux2_df)
# merge mean and sd force data
data_force_Sasaki_df <- full_join(data_force_mean_Sasaki_df, data_force_sd_Sasaki_df,
by=join_by(age,cond,isi))
data_force_Sasaki_df <- data_force_Sasaki_df %>%
mutate(force_cv = force_sd/force_mean) %>%
select(age,isi,cond,force_mean,force_sd,force_cv)
# merge Sasaki2010 ITI and force data
data_Sasaki_df <- full_join(data_force_Sasaki_df, data_iti_Sasaki_df, by=join_by(age,cond,isi)) %>%
# transform to SD of asynchronies
mutate(asyn_sd = iti_sd/sqrt(2*(1-autocorr_lag1)))
# data from Inui et al 2002
data_force_Inui_df = read.csv("Inui 2002 figure 5A.dat", sep='\t', header=TRUE) # cv of force
aux1_df = read.csv("Inui 2002 figure 2B.dat", sep='\t', header=TRUE) # mean intertap interval
aux2_df = read.csv("Inui 2002 figure 5B.dat", sep='\t', header=TRUE) # cv of intertap interval
# merge Inui2002 ITI data
data_iti_Inui_df <- full_join(aux1_df, aux2_df, by=join_by(tap,isi)) %>%
mutate(iti_sd = iti_mean*iti_cv,
# transform to SD of asynchronies
asyn_sd = iti_sd/sqrt(2*(1-autocorr_lag1)))
# merge Inui2002 ITI and force data
data_Inui_df <- full_join(data_iti_Inui_df, data_force_Inui_df, by=join_by(tap,isi)) %>%
# remove tap=4 due to different experimental condition
filter(tap!=4)
# merge all data
data_df <- full_join(data_Sasaki_df, data_Inui_df, by=join_by(isi,force_cv,iti_sd,asyn_sd))
# compute correlation between asyn_sd and Force_cv
corr_SDA_CVF <- cor(data_df$force_cv, data_df$asyn_sd, method='pearson')
# estimate number of participants
z_onetailed <- 1.64
z_pow80 <- 0.84
N_estim <- ceiling(4*(z_onetailed+z_pow80)^2/log((1+corr_SDA_CVF)/(1-corr_SDA_CVF)) + 3);
print(paste('Correlation coefficient SD_A vs CV_F from literature =',corr_SDA_CVF))
print(paste('Estimated number of participants:',N_estim))
setwd('labo/proyectos/fuerza/manuscrito/repositorio/analysis/')
# set current directory to /analysis
library(tidyverse)
library(magrittr)
library(R.matlab)
library(lme4)
library(lmerTest)
library(car)
library(broom)
library(afex)
library(effectsize)
# data_path <- '/home/rodrigo/labo/proyectos/fuerza/manuscrito/repositorio/data/'
data_path <- '../data/'
condition_colnames <- c('Normal-NoFBK','Normal-WithFBK','High-NoFBK','High-WithFBK')
subject_df <- data.frame(c(c(1:22),c(1:22),c(23:44),c(23:44)))
colnames(subject_df) <- 'Subject'
levels_A <- c('Normal','High')
levels_F <- c('NoFBK','WithFBK')
# SDA data
data_sda_df <- data.frame(readMat(paste0(data_path,'STDASY.mat')))
colnames(data_sda_df) <- condition_colnames
data_sda_df <- data_sda_df %>%
pivot_longer(names(.), names_to=c('Attention','Feedback'),
names_sep='-', values_to='SDA',
cols_vary='slowest')
data_sda_df$Attention <- factor(data_sda_df$Attention, levels=levels_A)
data_sda_df$Feedback <- factor(data_sda_df$Feedback, levels=levels_F)
data_sda_df <- cbind(subject_df, data_sda_df %>% arrange(Attention,Feedback))
# F data
data_f_df <- data.frame(readMat(paste0(data_path,'F1.mat')))
colnames(data_f_df) <- condition_colnames
data_f_df <- data_f_df %>%
pivot_longer(names(.), names_to=c('Attention','Feedback'),
names_sep='-', values_to='F',
cols_vary='slowest')
data_f_df$Attention <- factor(data_f_df$Attention, levels=levels_A)
data_f_df$Feedback <- factor(data_f_df$Feedback, levels=levels_F)
data_f_df <- cbind(subject_df, data_f_df %>% arrange(Attention,Feedback))
# SDF data
data_sdf_df <- data.frame(readMat(paste0(data_path,'STDF1.mat')))
colnames(data_sdf_df) <- condition_colnames
data_sdf_df <- data_sdf_df %>%
pivot_longer(names(.), names_to=c('Attention','Feedback'),
names_sep='-', values_to='SDF',
cols_vary='slowest')
data_sdf_df$Attention <- factor(data_sdf_df$Attention, levels=levels_A)
data_sdf_df$Feedback <- factor(data_sdf_df$Feedback, levels=levels_F)
data_sdf_df <- cbind(subject_df, data_sdf_df %>% arrange(Attention,Feedback))
# CVF data
data_cvf_df <- data.frame(readMat(paste0(data_path,'CVF1INTRA.mat')))
colnames(data_cvf_df) <- condition_colnames
data_cvf_df <- data_cvf_df %>%
pivot_longer(names(.), names_to=c('Attention','Feedback'),
names_sep='-', values_to='CVF',
cols_vary='slowest')
data_cvf_df$Attention <- factor(data_cvf_df$Attention, levels=levels_A)
data_cvf_df$Feedback <- factor(data_cvf_df$Feedback, levels=levels_F)
data_cvf_df <- cbind(subject_df, data_cvf_df %>% arrange(Attention,Feedback))
# MSJ data
data_msj_df <- data.frame(readMat(paste0(data_path,'MSJ.mat')))
colnames(data_msj_df) <- condition_colnames
data_msj_df <- data_msj_df %>%
pivot_longer(names(.), names_to=c('Attention','Feedback'),
names_sep='-', values_to='MSJ',
cols_vary='slowest')
data_msj_df$Attention <- factor(data_msj_df$Attention, levels=levels_A)
data_msj_df$Feedback <- factor(data_msj_df$Feedback, levels=levels_F)
data_msj_df <- cbind(subject_df, data_msj_df %>% arrange(Attention,Feedback))
# join SDA, F, SDF, CVF, MSJ
data_df <- list(data_sda_df, data_f_df, data_sdf_df, data_cvf_df, data_msj_df) %>%
reduce(inner_join, by = join_by(Subject, Attention, Feedback)) %>%
# create variables for afex and effectsize
mutate(CVF_center = CVF-mean(CVF),
F_center = F-mean(F),
Finv = 1/F,
Finv_center = Finv-mean(Finv),
lognormF = log(F/max(F)),
lognormMSJ = log(MSJ/max(MSJ)),
lognormF_center = lognormF-mean(lognormF),
Subject_aov = row_number())
# SDA vs CVF
model_SDACVF <- aov_4(SDA ~ CVF_center + Attention + Feedback
+ CVF_center:Attention + CVF_center:Feedback + Attention:Feedback
+ (1|Subject_aov),
data = data_df,
covariate = 'CVF_center',
observed = c('CVF_center'),
factorize = FALSE,
anova_table = list(es=c("ges","pes"), sig_symbols=rep("",4)))
model_SDACVF_etap <- eta_squared(model_SDACVF, partial=TRUE, alternative='two.sided')
model_SDACVF_etag <- eta_squared(model_SDACVF, generalized=TRUE, alternative='two.sided')
print(model_SDACVF_etap)
print(model_SDACVF_etag)
## SDF vs F
model_SDFF <- aov_4(SDF ~ F_center + Attention + Feedback
+ F_center:Attention + F_center:Feedback + Attention:Feedback
+ (1|Subject_aov),
data = data_df,
covariate = 'F_center',
observed = c('F_center'),
factorize = FALSE,
anova_table = list(es=c("ges","pes"), sig_symbols=rep("",4)))
model_SDFF_etap <- eta_squared(model_SDFF, partial=TRUE, alternative='two.sided')
model_SDFF_etag <- eta_squared(model_SDFF, generalized=TRUE, alternative='two.sided')
print(model_SDFF_etap)
print(model_SDFF_etag)
## CVF vs 1/F
model_CVFF <- aov_4(CVF ~ Finv_center + Attention + Feedback
+ Finv_center:Attention + Finv_center:Feedback + Attention:Feedback
+ (1|Subject_aov),
data = data_df,
covariate = 'Finv_center',
observed = c('Finv_center'),
factorize = FALSE,
anova_table = list(es=c("ges","pes"), sig_symbols=rep("",4)))
model_CVFF_etap <- eta_squared(model_CVFF, partial=TRUE, alternative='two.sided')
model_CVFF_etag <- eta_squared(model_CVFF, generalized=TRUE, alternative='two.sided')
print(model_CVFF_etap)
print(model_CVFF_etag)
## MSJ vs F
model_MSJF <- aov_4(lognormMSJ ~ lognormF_center + Attention + Feedback
+ lognormF_center:Attention + lognormF_center:Feedback + Attention:Feedback
+ (1|Subject_aov),
data = data_df,
covariate = 'lognormF_center',
observed = c('lognormF_center'),
factorize = FALSE,
anova_table = list(es=c("ges","pes"), sig_symbols=rep("",4)))
model_MSJF_etap <- eta_squared(model_MSJF, partial=TRUE, alternative='two.sided')
model_MSJF_etag <- eta_squared(model_MSJF, generalized=TRUE, alternative='two.sided')
print(model_MSJF_etap)
print(model_MSJF_etag)
